{
  "hash": "0b7893614f74091f0cc9b5e9dac83434",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat:\n  html:\n    code-fold: false\necho: true\n---\n\n# The Whole Game {#sec-whole-game}\n\nThis chapter on the main website is a high-level tour of the modeling process.\nWe'll follow the same pattern here by analyzing the same data.\nBut in Python!\nWe won't be able to reproduce everything, but at a high level you'll see the same key points, and how common python packages work.\n\n## Load the Data\n\nStart by loading the data;^[\nWe've opted to use the comma-separated values (CSV) format\nbecause that's easily loaded in many programs;\nthere are other formats that hold more information (like column data types)\nand are more efficient.]\npandas is the standard dataframe package in python.^[\nbut again, fancier things exist, perhaps most notably `polars`\n]\n\n::: {#load-data-from-root .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\ndeliveries = pd.read_csv(\"data/deliveries.csv\", index_col=0)\ndeliveries.head()\n```\n:::\n\n\n::: {#20122413 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_delivery</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>distance</th>\n      <th>item_01</th>\n      <th>item_02</th>\n      <th>item_03</th>\n      <th>item_04</th>\n      <th>item_05</th>\n      <th>item_06</th>\n      <th>...</th>\n      <th>item_18</th>\n      <th>item_19</th>\n      <th>item_20</th>\n      <th>item_21</th>\n      <th>item_22</th>\n      <th>item_23</th>\n      <th>item_24</th>\n      <th>item_25</th>\n      <th>item_26</th>\n      <th>item_27</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>16.1106</td>\n      <td>11.899</td>\n      <td>Thu</td>\n      <td>3.15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22.9466</td>\n      <td>19.230</td>\n      <td>Tue</td>\n      <td>3.69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30.2882</td>\n      <td>18.374</td>\n      <td>Fri</td>\n      <td>2.06</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33.4266</td>\n      <td>15.836</td>\n      <td>Thu</td>\n      <td>5.97</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>27.2255</td>\n      <td>19.619</td>\n      <td>Fri</td>\n      <td>2.52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>\n```\n:::\n:::\n\n\npandas provides plotting utilities, wrapping matplotlib:\n\n::: {#cell-fig-histogram-of-outcome .cell execution_count=3}\n``` {.python .cell-code}\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfig, ax = plt.subplots(1, 2, sharey=True)\ndeliveries['time_to_delivery'].hist(bins=30, ax=ax[0], label=\"time to delivery\")\ndeliveries['time_to_delivery'].apply(np.log).hist(bins=30, ax=ax[1], label=\"log(time to delivery)\")\nax[0].set_xlabel(\"time_to_delivery\")\nax[1].set_xlabel(\"log(time_to_delivery)\")\nax[0].set_ylabel(\"count\")\nplt.show();\n```\n\n::: {.cell-output .cell-output-display}\n![](whole-game_files/figure-html/fig-histogram-of-outcome-output-1.png){#fig-histogram-of-outcome width=527 height=374}\n:::\n:::\n\n\nReading from a CSV can't intuit everything we'd like.\nThe `day` column, the day of the week, was loaded as strings.\nIt'll be helpful in some places to cast them to a `categorical` type.\n\n::: {#day-to-ordinal .cell execution_count=4}\n``` {.python .cell-code}\ndeliveries['day'] = (\n    deliveries['day']\n    .astype('category')\n    .cat.set_categories(\n        ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n        ordered=True,\n    )\n)\n```\n:::\n\n\n## Data Spending\n\nsklearn provides `train_test_split` for simple splits, and several other cross-validation generators.\n\n`train_test_split` doesn't currently support stratifying on a continuous outcome.\nIt's probably not really needed here: with a large dataset randomness will generally work just fine.\nBut we can stratify on the binned outcome^[\n  we use quartiles to match tidymodels, see [docs](https://rsample.tidymodels.org/reference/initial_validation_split.html#arguments)\n]:\n\n::: {#data-split .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\ndelivery_train_val, delivery_test = train_test_split(\n    deliveries,\n    test_size=0.2,\n    random_state=42,\n    stratify=pd.qcut(deliveries['time_to_delivery'], 4),\n)\ndelivery_train, delivery_val = train_test_split(\n    delivery_train_val,\n    test_size=0.2 / 0.8,\n    random_state=42,\n    stratify=pd.qcut(delivery_train_val['time_to_delivery'], 4),\n)\n\nprint(len(delivery_train), len(delivery_val), len(delivery_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6006 2003 2003\n```\n:::\n:::\n\n\n## Exploratory Data Analysis\n\n### Distance and datetime features\n\nPlotting smoothed trendlines isn't so easy in pandas+matplotlib^[\nthe latter [have expressed concern](https://github.com/matplotlib/matplotlib/issues/19384#issuecomment-768674677)\nover making up information\nas well as possibly exploding the number of parameters needed for different uses];\nfor now we avoid additional packages, \nrelying on just the scatter plots in the top charts\nand adding a binned trend line for hour-vs-day interaction.\n\n::: {#cell-fig-eda-plots .cell execution_count=6}\n``` {.python .cell-code}\nfrom matplotlib import pyplot as plt\n\nfig, ax = plt.subplots(2, 2, figsize=(8, 6))\n\ndelivery_train.plot.scatter(\n    x='distance',\n    y='time_to_delivery',\n    alpha=0.1,\n    ax=ax[0, 0],\n)\n\ndelivery_train.plot.scatter(\n    x='hour',\n    y='time_to_delivery',\n    alpha=0.1,\n    ax=ax[0, 1],\n)\nax[0, 1].set_ylabel('')\n\ndelivery_train.boxplot(\n    column='time_to_delivery',\n    by='day',\n    ax=ax[1, 0],\n)\nax[1, 0].set_title('')\n\n\n# without fitting smoothers (another plotting package would help here),\n# we'll bin the `hour` per `day` and line-plot the mean target\ntemp = delivery_train.copy()\ntemp['hour_bin'] = (\n    temp['hour']\n    .transform(pd.qcut, q=8)\n    .apply(lambda x: x.mid)\n    .astype('float')\n)\ngrouped = (\n    temp\n    .groupby(['day', 'hour_bin'], observed=True)\n    ['time_to_delivery']\n    .mean()\n    .reset_index('hour_bin')\n    .groupby('day', observed=True)\n)\nfor day, data in grouped:\n    data.plot.line(x='hour_bin', y='time_to_delivery', label=day, ax=ax[1, 1])\nplt.legend()\n\nplt.tight_layout()\nplt.suptitle('EDA plots')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](whole-game_files/figure-html/fig-eda-plots-output-1.png){#fig-eda-plots width=758 height=569}\n:::\n:::\n\n\n### Bootstrap confidence intervals for item effects\n\n\n\nDefine the metric, make bootstrap samples and apply the metric:\n\n::: {#11f5fb17 .cell execution_count=8}\n``` {.python .cell-code}\ndef rel_increase_time_item(df, col):\n    \"\"\"Computes the relative increase to delivery time when\n    the item for column `col` is present.\"\"\"\n    return (\n        df[['time_to_delivery']]\n        .groupby(df[col] > 0)\n        .mean()\n        .apply(lambda x: x[True] / x[False] - 1)\n        .item()\n    )\n\nresample_stats = []\nfor _ in range(1001):\n    resample = delivery_train.sample(frac=1, replace=True)\n    stat = {}\n    for col in [col for col in resample.columns if col[:5] == \"item_\"]:\n        stat[col] = rel_increase_time_item(resample, col)\n    resample_stats.append(stat)\nresample_stats = pd.DataFrame(resample_stats)\nresample_stats.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_01</th>\n      <th>item_02</th>\n      <th>item_03</th>\n      <th>item_04</th>\n      <th>item_05</th>\n      <th>item_06</th>\n      <th>item_07</th>\n      <th>item_08</th>\n      <th>item_09</th>\n      <th>item_10</th>\n      <th>...</th>\n      <th>item_18</th>\n      <th>item_19</th>\n      <th>item_20</th>\n      <th>item_21</th>\n      <th>item_22</th>\n      <th>item_23</th>\n      <th>item_24</th>\n      <th>item_25</th>\n      <th>item_26</th>\n      <th>item_27</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.059837</td>\n      <td>0.027667</td>\n      <td>0.016086</td>\n      <td>0.012144</td>\n      <td>0.007851</td>\n      <td>0.018182</td>\n      <td>0.026414</td>\n      <td>0.006065</td>\n      <td>0.030333</td>\n      <td>0.046600</td>\n      <td>...</td>\n      <td>0.011364</td>\n      <td>-0.038378</td>\n      <td>0.020940</td>\n      <td>0.028779</td>\n      <td>0.019817</td>\n      <td>0.015285</td>\n      <td>0.044199</td>\n      <td>0.020167</td>\n      <td>0.046261</td>\n      <td>0.063177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.055689</td>\n      <td>0.018290</td>\n      <td>-0.005845</td>\n      <td>-0.004415</td>\n      <td>0.005912</td>\n      <td>0.010217</td>\n      <td>0.015990</td>\n      <td>-0.004823</td>\n      <td>0.028485</td>\n      <td>0.058809</td>\n      <td>...</td>\n      <td>0.000547</td>\n      <td>-0.033938</td>\n      <td>0.024252</td>\n      <td>0.012355</td>\n      <td>0.045347</td>\n      <td>0.025344</td>\n      <td>0.026585</td>\n      <td>0.014412</td>\n      <td>0.027174</td>\n      <td>0.047914</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.045958</td>\n      <td>0.018760</td>\n      <td>-0.005201</td>\n      <td>-0.007170</td>\n      <td>-0.006138</td>\n      <td>0.014871</td>\n      <td>0.014589</td>\n      <td>0.010838</td>\n      <td>0.020212</td>\n      <td>0.059233</td>\n      <td>...</td>\n      <td>0.007720</td>\n      <td>-0.032272</td>\n      <td>0.025981</td>\n      <td>0.016507</td>\n      <td>0.034392</td>\n      <td>0.036563</td>\n      <td>0.026727</td>\n      <td>0.018097</td>\n      <td>0.027168</td>\n      <td>0.063526</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.056362</td>\n      <td>0.016948</td>\n      <td>0.002318</td>\n      <td>0.008138</td>\n      <td>-0.004072</td>\n      <td>0.022160</td>\n      <td>0.028072</td>\n      <td>-0.002906</td>\n      <td>0.043547</td>\n      <td>0.052030</td>\n      <td>...</td>\n      <td>0.020688</td>\n      <td>-0.041503</td>\n      <td>0.023177</td>\n      <td>0.014446</td>\n      <td>0.041065</td>\n      <td>0.010789</td>\n      <td>0.054260</td>\n      <td>0.010386</td>\n      <td>0.039690</td>\n      <td>0.059420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.052518</td>\n      <td>0.008144</td>\n      <td>0.011398</td>\n      <td>-0.000210</td>\n      <td>0.005164</td>\n      <td>0.015617</td>\n      <td>0.023016</td>\n      <td>0.015322</td>\n      <td>0.028712</td>\n      <td>0.059072</td>\n      <td>...</td>\n      <td>0.009432</td>\n      <td>-0.033609</td>\n      <td>0.009862</td>\n      <td>0.029123</td>\n      <td>0.020962</td>\n      <td>0.049653</td>\n      <td>0.016106</td>\n      <td>0.023727</td>\n      <td>0.024121</td>\n      <td>0.033796</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>\n```\n:::\n:::\n\n\nDefine the confidence intervals:\n\n::: {#e31141ec .cell execution_count=9}\n``` {.python .cell-code}\nci = resample_stats.apply(np.percentile, q=[5, 95])\nci.index = ['lower', 'upper']\n\nci = ci.T\nci['sample'] = [\n    rel_increase_time_item(delivery_train, col)\n    for col in delivery_train.columns if col[:5] == \"item_\"\n]\nci = ci.sort_values('sample')\n```\n:::\n\n\nPlot:\n\n::: {#cell-fig-item-effects .cell execution_count=10}\n``` {.python .cell-code}\nfig = plt.figure(figsize=(5, 12))\nfor y, (col, stats) in enumerate(ci.iterrows()):\n    plt.plot([stats['lower'], stats['upper']], [y, y], c='b')\n    plt.plot(stats['sample'], y, 'bo')\nplt.axvline(0, ls='--', c='r', alpha=0.2)\nplt.yticks(np.arange(len(ci)), labels=ci.index)\nplt.xlabel(\"Increase in delivery time when ordered\")\n\nplt.show();\n```\n\n::: {.cell-output .cell-output-display}\n![](whole-game_files/figure-html/fig-item-effects-output-1.png){#fig-item-effects width=454 height=947}\n:::\n:::\n\n\n## Model Development\n\nsklearn uses separate parameter slots for its independent and dependent variables, so\n\n::: {#417ee296 .cell execution_count=11}\n``` {.python .cell-code}\ny_var = 'time_to_delivery'\nX_train = delivery_train.drop(columns=y_var)\nX_val = delivery_val.drop(columns=y_var)\nX_test = delivery_test.drop(columns=y_var)\ny_train = delivery_train[y_var]\ny_val = delivery_val[y_var]\ny_test = delivery_test[y_var]\n```\n:::\n\n\n### Linear model\n\nWe use sklearn's `OneHotEncoder` to produce indicator columns (a.k.a. dummy variables, one-hot encoding) for the `day` variable.\n(pandas also has `make_dummies`, but this requires more work with the validation and test sets (and production),\nso we prefer to keep everything in sklearn.)\n\nFor splines, we have `SplineTransformer`.\n\nFor interaction terms, there's not a direct sklearn transformer.\nWe'll use a `FunctionTransformer` and define the transformation function directly.^[\n  We could also use `PolynomialFeatures` here,\n  with degree 2 and `interaction_only=True` to prevent $\\mathrm{feature}^2$ terms;\n  that would include things like\n  interactions of Monday with Wednesday,\n  or two spline bases,\n  which we could probably clean up downstream,\n  but this will be a little nicer.\n]\n\nTo apply preprocessors to different subsets of columns, we use `ColumnTransformer`.\n\n::: {#a07ca90f .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn import set_config\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, SplineTransformer, FunctionTransformer\n\nset_config(transform_output=\"pandas\")\n\nohe = OneHotEncoder(\n    sparse_output=False,\n    handle_unknown='ignore',\n)\nspl = SplineTransformer(knots='quantile')\n\ndef interactions(X):\n    for day_col in [col for col in X.columns if col[:4] == 'day_']:\n        for hour_basis in [col for col in X.columns if col[:5] == 'hour_']:\n            X[f'{day_col}*{hour_basis}'] = X[day_col] * X[hour_basis]\n    return X\n\nint_tfm = FunctionTransformer(interactions, check_inverse=False)\n\npreproc_lr = Pipeline([\n    ('step_1', ColumnTransformer(\n        [\n            ('ohe', ohe, ['day']),\n            ('spl', spl, ['hour']),\n        ],\n        remainder='passthrough',\n        verbose_feature_names_out=False,\n        )\n    ),\n    ('interact', int_tfm),\n])\n\npreproc_lr\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;step_1&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;ohe&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse_output=False),\n                                                  [&#x27;day&#x27;]),\n                                                 (&#x27;spl&#x27;,\n                                                  SplineTransformer(knots=&#x27;quantile&#x27;),\n                                                  [&#x27;hour&#x27;])],\n                                   verbose_feature_names_out=False)),\n                (&#x27;interact&#x27;,\n                 FunctionTransformer(check_inverse=False,\n                                     func=&lt;function interactions at 0x000001BC4DA0AFC0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;step_1&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;ohe&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse_output=False),\n                                                  [&#x27;day&#x27;]),\n                                                 (&#x27;spl&#x27;,\n                                                  SplineTransformer(knots=&#x27;quantile&#x27;),\n                                                  [&#x27;hour&#x27;])],\n                                   verbose_feature_names_out=False)),\n                (&#x27;interact&#x27;,\n                 FunctionTransformer(check_inverse=False,\n                                     func=&lt;function interactions at 0x000001BC4DA0AFC0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">step_1: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;ohe&#x27;,\n                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n                                               sparse_output=False),\n                                 [&#x27;day&#x27;]),\n                                (&#x27;spl&#x27;, SplineTransformer(knots=&#x27;quantile&#x27;),\n                                 [&#x27;hour&#x27;])],\n                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;day&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">spl</label><div class=\"sk-toggleable__content\"><pre>[&#x27;hour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SplineTransformer</label><div class=\"sk-toggleable__content\"><pre>SplineTransformer(knots=&#x27;quantile&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(check_inverse=False,\n                    func=&lt;function interactions at 0x000001BC4DA0AFC0&gt;)</pre></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\nAll sklearn estimators (both transformers and model objects) implement a `fit` method that learns statistics/parameters from the data.  Transformers provide `transform` for applying their transformations to data (whether training or test data; for training data, `fit_transform` is available and most often means just `fit` then `transform`).  Model objects provide `predict` (and probabilistic classifiers provide `predict_proba`).  There are many other methods and attributes, but these will get us through the rest of this chapter.\n\nLet's see what the fully preprocessed data looks like.\n\n::: {#4d5b8fe1 .cell execution_count=13}\n``` {.python .cell-code}\npreproc_lr.fit_transform(X_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day_Fri</th>\n      <th>day_Mon</th>\n      <th>day_Sat</th>\n      <th>day_Sun</th>\n      <th>day_Thu</th>\n      <th>day_Tue</th>\n      <th>day_Wed</th>\n      <th>hour_sp_0</th>\n      <th>hour_sp_1</th>\n      <th>hour_sp_2</th>\n      <th>...</th>\n      <th>day_Tue*hour_sp_4</th>\n      <th>day_Tue*hour_sp_5</th>\n      <th>day_Tue*hour_sp_6</th>\n      <th>day_Wed*hour_sp_0</th>\n      <th>day_Wed*hour_sp_1</th>\n      <th>day_Wed*hour_sp_2</th>\n      <th>day_Wed*hour_sp_3</th>\n      <th>day_Wed*hour_sp_4</th>\n      <th>day_Wed*hour_sp_5</th>\n      <th>day_Wed*hour_sp_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5732</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4480</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.006219</td>\n      <td>0.294690</td>\n      <td>0.612966</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7337</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.015240</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8762</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.008700</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2742</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.035889</td>\n      <td>0.480137</td>\n      <td>0.465214</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8232</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000036</td>\n      <td>0.120192</td>\n      <td>0.637531</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6660</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002236</td>\n      <td>0.227557</td>\n      <td>0.640921</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.083970</td>\n      <td>0.588468</td>\n      <td>0.325075</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8066</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.004694</td>\n      <td>0.295272</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6006 rows × 91 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe can put that frame directly into a model, or again wrap the preprocessor in a pipeline with the model (which will make predicting slightly easier, as the transformations will happen under the hood).\n\n::: {#37181fe2 .cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n\npipe_lr = Pipeline([\n    ('preproc', preproc_lr),\n    ('linear_reg', LinearRegression()),\n])\npipe_lr.fit(X_train, y_train)\n\ny_pred = pipe_lr.predict(X_val)\nmean_absolute_error(y_true=y_val, y_pred=y_pred)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n1.6421489340208437\n```\n:::\n:::\n\n\nTake a look at a calibration plot, the actual-vs-predicted values:\n\n::: {#cell-fig-calibration .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.metrics import PredictionErrorDisplay\nPredictionErrorDisplay.from_predictions(\n    y_true=y_val,\n    y_pred=y_pred,\n    kind='actual_vs_predicted',\n    scatter_kwargs={'alpha': 0.1},\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](whole-game_files/figure-html/fig-calibration-output-1.png){#fig-calibration width=531 height=374}\n:::\n:::\n\n\n### Random forest\n\nsklearn doesn't have a model-based recursive partitioning like cubist;\nthere is a different python package just for that,\nbut to stick to sklearn for now let's fit instead a random forest.\nRandom forests build binary trees like cubist,\nbut with constant predictions from each leaf\n instead of the linear models that cubist produces.\nTo reach similar performance then, we'll want deeper trees.\n\nAs in the book, this tree-based model doesn't necessitate as much transformation to perform well.\nHowever, at time of writing sklearn's random forest doesn't handle categorical features,\nso we'll need to one-hot encode `day` still.\n\nAnd intuitively the _number_ of items ought to also be important;\nwhile the linear model gets that for free (just the sum of the `item_` columns),\nand a tree can approximate it arbitrarily closely,\nit can be beneficial to the learning procedure to expose this as a feature directly.\nWe can add that in the pipeline as another `FunctionTransformer`.\n\n::: {#dc673ed7 .cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import make_column_selector\n\nrf = RandomForestRegressor(\n    max_depth=15,\n    n_estimators=100,\n    random_state=42,\n)\n\ndef item_count(X):\n    X['item_count'] = X.sum(axis=1)\n    return X\n\npreproc_rf = ColumnTransformer(\n    [\n        ('ohe', ohe, ['day']),\n        ('items', FunctionTransformer(item_count), make_column_selector(pattern='item_*')),\n    ],\n    remainder='passthrough',\n    verbose_feature_names_out=False,\n)\n\npipe_rf = Pipeline([\n    ('preproc', preproc_rf),\n    ('rand_forest', rf),\n])\n\npipe_rf.fit(X_train, y_train)\n\ny_pred = pipe_rf.predict(X_val)\nmean_absolute_error(y_true=y_val, y_pred=y_pred)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n1.4992085511625766\n```\n:::\n:::\n\n\nAdding the item count appears (on the validation set) to have helped a bit.\nTaking into account our analysis of item presence,\nwe might modify the count to exclude item 19,\nor increase the weight on item 10, etc.\nBut at that point the trees might already be making the relevant modifications.\n\n### Neural network\n\nsklearn isn't the best package for neural networks,\nbut it does provide a simple implementation:\n\n::: {#b65e2f14 .cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.neural_network import MLPRegressor\nnn = MLPRegressor(\n    max_iter=500,\n    learning_rate_init=0.01,\n    random_state=42,\n)\n```\n:::\n\n\nAs in the book, we won't get into the large space of hyperparameters,\nand just tune the number of neurons in a single hidden layer.\nsklearn offers `GridSearchCV` for tuning hyperparameters in a grid style,\nor `RandomizedSearchCV` for a random search.\nOther packages offer other strategies.\n\nThe tuners in sklearn use k-fold cross-validation by default.\nWhile it's possible to tune using a fixed validation set,\nwe'll just use the k-fold splitting of the training set to score hyperparameters,\nand score the best hyperparameter against our validation set.\n\n::: {#644e3024 .cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\npreproc_nn = ColumnTransformer(\n    [('ohe', ohe, ['day'])],\n    remainder=StandardScaler(),\n)\n\npipe_nn = Pipeline([\n    ('preproc', preproc_nn),\n    ('neural_net', nn),\n])\n\n# setting hyperparameters for a pipeline\n# uses <step_name>__<parameter>\nparams = {\n    'neural_net__hidden_layer_sizes': [(k,) for k in range(2, 10)],\n}\n\n# By default the search will use k-fold cross-validation on its training set.\n# If we want to score on the already-defined validation set,\n# we need to pass train+val into `fit` and specify the validation mask in the `cv` parameter.\ndelivery_train_val\nsearch = GridSearchCV(\n    estimator=pipe_nn,\n    param_grid=params,\n    cv=[[list(range(len(X_train))), list(range(len(X_train), len(X_train) + len(X_val)))]],\n    scoring='neg_mean_absolute_error',\n    n_jobs=3,\n)\n\nsearch.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\nsearch.best_score_\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n-1.5896399846317641\n```\n:::\n:::\n\n\nTo find out more about the search, we have a look at the attribute `cv_results_`:\n\n::: {#9d5a4e61 .cell execution_count=19}\n``` {.python .cell-code}\ncv_results_frame = pd.DataFrame(search.cv_results_)\ncv_results_frame\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_neural_net__hidden_layer_sizes</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.961829</td>\n      <td>0.0</td>\n      <td>0.028263</td>\n      <td>0.0</td>\n      <td>(2,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (2,)}</td>\n      <td>-2.846601</td>\n      <td>-2.846601</td>\n      <td>0.0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.130723</td>\n      <td>0.0</td>\n      <td>0.031076</td>\n      <td>0.0</td>\n      <td>(3,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (3,)}</td>\n      <td>-2.810811</td>\n      <td>-2.810811</td>\n      <td>0.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.660357</td>\n      <td>0.0</td>\n      <td>0.029812</td>\n      <td>0.0</td>\n      <td>(4,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (4,)}</td>\n      <td>-1.799978</td>\n      <td>-1.799978</td>\n      <td>0.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.921726</td>\n      <td>0.0</td>\n      <td>0.026736</td>\n      <td>0.0</td>\n      <td>(5,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (5,)}</td>\n      <td>-2.648188</td>\n      <td>-2.648188</td>\n      <td>0.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.323614</td>\n      <td>0.0</td>\n      <td>0.026697</td>\n      <td>0.0</td>\n      <td>(6,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (6,)}</td>\n      <td>-1.763588</td>\n      <td>-1.763588</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.643244</td>\n      <td>0.0</td>\n      <td>0.026805</td>\n      <td>0.0</td>\n      <td>(7,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (7,)}</td>\n      <td>-1.677239</td>\n      <td>-1.677239</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5.286923</td>\n      <td>0.0</td>\n      <td>0.021809</td>\n      <td>0.0</td>\n      <td>(8,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (8,)}</td>\n      <td>-1.602884</td>\n      <td>-1.602884</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.278420</td>\n      <td>0.0</td>\n      <td>0.021161</td>\n      <td>0.0</td>\n      <td>(9,)</td>\n      <td>{'neural_net__hidden_layer_sizes': (9,)}</td>\n      <td>-1.589640</td>\n      <td>-1.589640</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nPlotting from that dataframe:\n\n::: {#cell-fig-NN-hyperparameter-results .cell execution_count=20}\n``` {.python .cell-code}\n# extract the numeric hidden layer size\n# from the tuple-typed hyperparameter\ncv_results_frame['hidden_layer_size'] = cv_results_frame[\n    'param_neural_net__hidden_layer_sizes'\n].apply(lambda x: x[0])\n\n# convert back from scorer neg_mae to mae\ncv_results_frame['mae'] = - cv_results_frame['mean_test_score']\n\nfrom matplotlib import colormaps\nfig, ax = plt.subplots(1)\ncv_results_frame.plot.scatter(\n    x='hidden_layer_size',\n    y='mae',\n    ax=ax,\n)\nplt.legend()\nax.set_ylabel(\"MAE\")\nplt.show();\n```\n\n::: {.cell-output .cell-output-display}\n![](whole-game_files/figure-html/fig-nn-hyperparameter-results-output-1.png){#fig-nn-hyperparameter-results width=515 height=374}\n:::\n:::\n\n\n",
    "supporting": [
      "whole-game_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}